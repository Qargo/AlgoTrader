{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlgoTrader - End Of The Day Prediction Trading by using reinforcement learning AI and based on FinRL lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_single_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I am using local source code of the finrl library. This will allow us to add additional loaders, technical indicators, sentiment and custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if you are running this in Google Colab, please enable installation of FinRL lib\n",
    "# !pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Install following packages\n",
    " * Yahoo Finance API\n",
    " * pandas\n",
    " * numpy\n",
    " * matplotlib\n",
    " * stockstats\n",
    " * OpenAI gym\n",
    " * stable-baselines\n",
    " * tensorflow\n",
    " * pyfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lets check if we have all packages installed, and if not lets install them\n",
    "import pkg_resources\n",
    "installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "required = {'yfinance', 'pandas', 'matplotlib', 'stockstats','stable-baselines','gym','tensorflow'}\n",
    "missing = required - installedPackages\n",
    "if missing:\n",
    "    !pip install yfinance\n",
    "    !pip install pandas\n",
    "    !pip install matplotlib\n",
    "    !pip install stockstats\n",
    "    !pip install gym\n",
    "    !pip install stable-baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "# import itertools\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# add FinRL-Library path\n",
    "sys.path.append(\"FinRL-Library\")\n",
    "\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "from finrl.trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Basic setup\n",
    "#Disable warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# add following folders\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download end of the day trading data. For this I am using YahooDawnloader function from the marketdata package, that is\n",
    "implemented in finrl library. This function is actually using fyahoo library.\n",
    "\n",
    "Todo:\n",
    " - [ ] add loader for IEX Cloud\n",
    "\n",
    " -----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# From config.py file get following:\n",
    "\n",
    "# start_date\n",
    "START_DATE = config.START_DATE\n",
    "\n",
    "# end_date\n",
    "END_DATE = config.END_DATE\n",
    "\n",
    "# list of stocks\n",
    "# STOCK_LIST = config.MULTIPLE_STOCK_TICKER\n",
    "STOCK_LIST = config.DOW_30_TICKER\n",
    "\n",
    "print(STOCK_LIST)\n",
    "\n",
    "# Download and save the data in a pandas DataFrame:\n",
    "data_frame = YahooDownloader(start_date = START_DATE,\n",
    "                             end_date = END_DATE,\n",
    "                             ticker_list = STOCK_LIST).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing\n",
    "data and to do feature engineering in order to convert the data into a model-ready state.\n",
    "* FinRL uses a class FeatureEngineer to preprocess the data\n",
    "* Add technical indicators to the dataset. In practical trading, various information needs to be taken into account,\n",
    "  for example the historical stock prices, current holding shares, technical indicators, etc.\n",
    "\n",
    "---\n",
    "\n",
    "class FeatureEngineer:\n",
    "Provides methods for preprocessing the stock price data\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            data downloaded from Yahoo API\n",
    "        feature_number : int\n",
    "            number of features we used\n",
    "        use_technical_indicator : boolean\n",
    "            we technical indicator or not\n",
    "        use_turbulence : boolean\n",
    "            use turbulence index or not\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess_data()\n",
    "        main method to do the feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical Indicators\n",
    "* FinRL uses stockstats to calculate technical indicators such as:\n",
    " * Moving Average Convergence Divergence (MACD) - this indicator is used to identify buying and selling cycle. If the\n",
    "   rice goes up during the selling cycle that shows strong demand. MACD belongs to Trend Indicators.\n",
    " * Relative Strength Index (RSI) - when RSI is above 70 it is considered to be overbought and when it is below 30 it\n",
    "   is considered to be oversold. RSI belongs to Momentum Indicators.\n",
    " * Average Directional Index (ADX) - The average directional index (ADX) is a technical analysis indicator used by some\n",
    "   traders to determine the strength of a trend. ADX belongs to Trend Indicators. For more go here:\n",
    "   https://www.investopedia.com/terms/a/adx.asp\n",
    " * Commodity Channel Index (CCI) - is a momentum based oscillator used to help determine when an investment vehicle is\n",
    "   reaching a condition of being overbought or oversold. It is also used to assess price trend direction and strength.\n",
    "   This information allows traders to determine if they want to enter or exit a trade, refrain from taking a trade, or\n",
    "   add to an existing position. In this way, the indicator can be used to provide trade signals when it acts in a\n",
    "   certain way. For more go here: https://www.investopedia.com/terms/c/commoditychannelindex.asp\n",
    "* stockstats library: supplies a wrapper StockDataFrame based on the pandas.DataFrame with inline stock\n",
    "  statistics/indicators support. Supported statistics/indicators are:\n",
    "  * change (in percent)\n",
    "  * delta\n",
    "  * permutation (zero based)\n",
    "  * log return\n",
    "  * max in range\n",
    "  * min in range\n",
    "  * middle = (close + high + low) / 3\n",
    "  * compare: le, ge, lt, gt, eq, ne\n",
    "  * count: both backward(c) and forward(fc)\n",
    "  * SMA: simple moving average\n",
    "  * EMA: exponential moving average\n",
    "  * MSTD: moving standard deviation\n",
    "  * MVAR: moving variance\n",
    "  * RSV: raw stochastic value\n",
    "  * RSI: relative strength index\n",
    "  * KDJ: Stochastic oscillator\n",
    "  * Bolling: including upper band and lower band.\n",
    "  * MACD: moving average convergence divergence. Including signal and histogram. (see note)\n",
    "  * CR:\n",
    "  * WR: Williams Overbought/Oversold index\n",
    "  * CCI: Commodity Channel Index\n",
    "  * TR: true range\n",
    "  * ATR: average true range\n",
    "  * line cross check, cross up or cross down.\n",
    "  * DMA: Different of Moving Average (10, 50)\n",
    "  * DMI: Directional Moving Index, including\n",
    "  * +DI: Positive Directional Indicator\n",
    "  * -DI: Negative Directional Indicator\n",
    "  * ADX: Average Directional Movement Index\n",
    "  * ADXR: Smoothed Moving Average of ADX\n",
    "  * TRIX: Triple Exponential Moving Average\n",
    "  * TEMA: Another Triple Exponential Moving Average\n",
    "  * VR: Volatility Volume Ratio\n",
    "\n",
    "Todo:\n",
    " - [ ] add some additional Technical Indicators to the dataset.\n",
    "       https://www.visualcapitalist.com/12-types-technical-indicators-stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## we store the stockstats technical indicator column names in config.py\n",
    "tech_indicator_list=config.TECHNICAL_INDICATORS_LIST\n",
    "print(tech_indicator_list)\n",
    "\n",
    "feature_engineering = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list=tech_indicator_list,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature=False)\n",
    "\n",
    "processed = feature_engineering.preprocess_data(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_ticker = processed[\"tic\"].unique().tolist()\n",
    "# list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "# combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "# processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "# processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processed.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design your gym\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as\n",
    "a Markov Decision Process (MDP) problem. The training process involves observing stock price change, taking an action\n",
    "and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the\n",
    "trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to\n",
    "the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes\n",
    "three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be\n",
    "carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy\n",
    "and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or\n",
    "-10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a\n",
    "Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation. Split dataset on training data and trading data\n",
    "#### Training data: 2009-03-01 to 2018-12-31\n",
    "#### Trade data: 2019-01-01 to 2020-09-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_set = data_split(processed, config.START_DATE, config.START_TRADE_DATE)\n",
    "tradeing_set = data_split(processed, config.START_TRADE_DATE, config.END_DATE)\n",
    "print(len(training_set))\n",
    "print(len(tradeing_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tradeing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(training_set.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(tech_indicator_list)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_training_gym = StockTradingEnv(df=training_set, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_training, _ = e_training_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(env_training))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment for Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# e_tradeing_gym = StockTradingEnv(df=tradeing_set, turbulence_threshold=380, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on OpenAI Baselines and Stable Baselines. Stable Baselines is a\n",
    "  fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG, Multi-Agent DDPG, PPO, SAC, A2C and TD3.\n",
    "  We also allow users to design their own DRL algorithms by adapting these DRL algorithms. Instead of installing FinRL\n",
    "  lib I have included the source code and created my own version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env=env_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training: 5 models, A2C DDPG, PPO, TD3, SAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c,\n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained a2c model\n",
    "path_a2c = \"./\" + config.TRAINED_MODEL_DIR + \"/trained_a2c\"\n",
    "agent.save_model(model=trained_a2c, path=path_a2c)\n",
    "\n",
    "# delete trained a2c model\n",
    "del trained_a2c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg,\n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained ddpg model\n",
    "path_ddpg = \"./\" + config.TRAINED_MODEL_DIR + \"/trained_ddpg\"\n",
    "agent.save_model(model=trained_ddpg, path=path_ddpg)\n",
    "\n",
    "# delete trained ddpg model\n",
    "del trained_ddpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\", model_kwargs=PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo,\n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained ppo model\n",
    "path_ppo = \"./\" + config.TRAINED_MODEL_DIR + \"/trained_ppo\"\n",
    "agent.save_model(model=trained_ppo, path=path_ppo)\n",
    "\n",
    "# delete trained ppo model\n",
    "del trained_ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TD3_PARAMS = {\"batch_size\": 100,\n",
    "              \"buffer_size\": 1000000,\n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs=TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3,\n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained td3 model\n",
    "path_td3 = \"./\" + config.TRAINED_MODEL_DIR + \"/trained_td3\"\n",
    "agent.save_model(model=trained_td3, path=path_td3)\n",
    "\n",
    "# delete trained td3 model\n",
    "del trained_td3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs=SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac,\n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained sac model\n",
    "path_sac = \"./\" + config.TRAINED_MODEL_DIR + \"/trained_sac\"\n",
    "agent.save_model(model=trained_sac, path=path_sac)\n",
    "\n",
    "# delete trained sac model\n",
    "del trained_sac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be the 99% quantile of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_turbulence = processed[(processed.date < config.START_TRADE_DATE) & (processed.date >= config.START_DATE)]\n",
    "insample_turbulence = data_turbulence.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "insample_turbulence.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "turbulence_threshold = np.quantile(insample_turbulence.turbulence.values,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "turbulence_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2018-12 to tune the parameters once, so there is some alpha decay here as the length of trade date extends.\n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved a2c model\n",
    "model = DRLAgent.load_model(model_name=\"a2c\", path=path_a2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved ddpg model\n",
    "model = DRLAgent.load_model(model_name=\"ddpg\", path=path_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved ppo model\n",
    "model = DRLAgent.load_model(model_name=\"ppo\", path=path_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved td3 model\n",
    "model = DRLAgent.load_model(model_name=\"td3\", path=path_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved sac model\n",
    "model = DRLAgent.load_model(model_name=\"sac\", path=path_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "e_tradeing_gym = StockTradingEnv(df=tradeing_set, turbulence_threshold=250, **env_kwargs)\n",
    "\n",
    "env_trade, obs_trade = e_tradeing_gym.get_sb_env()\n",
    "\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=model, environment=e_tradeing_gym\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(df_account_value.shape)\n",
    "print(df_account_value.head())\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%Hh%M\")\n",
    "\n",
    "df_account_value.to_csv(\n",
    "    \"./\" + config.RESULTS_DIR + \"/df_account_value_\" + now + \".csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_actions.head())\n",
    "\n",
    "df_actions.to_csv(\"./\" + config.RESULTS_DIR + \"/df_actions_\" + now + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\" + config.RESULTS_DIR + \"/perf_stats_all_\" + now + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "backtest_plot(df_account_value,\n",
    "             baseline_ticker='^DJI',\n",
    "             baseline_start=config.START_TRADE_DATE,\n",
    "             baseline_end=config.END_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(ticker=\"^DJI\", start=config.START_TRADE_DATE, end=config.END_DATE)\n",
    "\n",
    "baseline_perf_stats = backtest_stats(baseline_df, value_col_name = 'close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
